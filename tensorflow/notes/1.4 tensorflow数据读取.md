# tensorflow队列和线程

## 队列

tensorflow有两种队列：
- tf.FIFOQueue：先进先出队列，按顺序出队列
- tf.RandomShuffleQueue：随机出队列

两个API的使用基本差不多，我们以FIFOQueue为例说明。

**核心API**

```python
FIFOQueue(capacity, dtypes, name='fifo_queue')
```

参数说明：
- capacity：整数。可能存储在此队列中的元素数量的上限。
- dtypes：DType对象列表。长度dtypes必须等于每个队列元素中的张量数,dtype的类型形状，决定了后面进队列元素形状。

 **FIFOQueue队列对象的相关方法**

- dequeue(name=None)：出队列
- enqueue(vals, name=None)：入队列
- enqueue_many(vals, name=None)：入队列，vals为列表或者元组
- size(name=None)：队列元素大小

我们通过一个示例来说明队列的作用，大致流程如下：
1. 创建一个可以存放3个数据的队列；
2. 放数据到队列中；
3. 定义一个从队列中取数据、将数据执行+1操作，然后将处理后的数据放回到队列中；

说明：tensor的操作有依赖性。

**示例代码**

```python
import tensorflow as tf
import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

# 1、定义队列，并放入数据
Q = tf.FIFOQueue(3, tf.float32)
enq_many = Q.enqueue_many([[0.1, 0.2, 0.3],])

# 2、定义读数据、取数据的过程、取数据+1，入队列
de_q= Q.dequeue()
data = de_q + 1
en_q = Q.enqueue(data)

with tf.Session() as sess:
    # 初始化队列
    sess.run(enq_many)

    # 处理数据
    for i in range(100):
        # tensorflow的操作有依赖性
        sess.run(en_q)
    # 训练数据
    for i in range(Q.size().eval()):
        print(sess.run(Q.dequeue()))
```

运行结果如下图所示；

```bash
33.2
33.3
34.1
```

## 线程

线程涉及到2个核心概念：队列管理器和线程协调器。

### 队列管理器QueueRunner

什么是队列管理器？
我们可以把我们的队列放到队列管理器中，并创建一个线程来运行我们的队列。

**核心API**
```python
# 创建一个QueueRunner
tf.train.QueueRunner(queue, enqueue_ops=None)
```

参数说明：
- queue：A Queue
- enqueue_ops：添加线程的队列操作列表，[]*2,指定两个线程

**QueueRunner相关方法**

create_threads(sess, coord=None,start=False)：创建线程来运行给定会话的入队操作

参数说明：
- start：布尔值，如果True启动线程；如果为False调用者必须调用start()启动线程 
- coord：线程协调器，后面线程管理需要用到
- return：线程的实例

### 线程协调器Coordinator

什么是线程协调器？
用来协调子线程和主线程，当我们在会话中开启子线程去做一些事情的时候，我们的会话执行完了，但是子线程还在运行，可是子线程的运行必须依赖会话，所以就会报错。有了线程协调器，我们可以在会话中等待子线程运行结束。

**核心API**

```python
# 线程协调员,实现一个简单的机制来协调一组线程的终止，返回一个Coordinator对象。
tf.train.Coordinator()
```

**Coordinator相关方法**

request_stop()：请求停止，等待子线程运行结束后停止。
should_stop()：检查是否要求停止，立即停止。
join(threads=None, stop_grace_period_secs=120) ：将子线程加入Coordinator，等待线程终止进行回收。

**示例代码**

```python
import tensorflow as tf
import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

# 1、定义1个队列，可以放1000个数据
Q = tf.FIFOQueue(1000, tf.float32)

# 2、定义要做的事情（例如：循环 +1， 放入线程）
var  = tf.Variable(0.0)
# 实现一个自增
data = tf.assign_add(var, tf.constant(1.0))
# 把数据放入队列
en_q = Q.enqueue(data)

# 3、定义队列管理器op, 指定多少个子线程，子线程该干什么事
qr = tf.train.QueueRunner(Q, enqueue_ops=[en_q] * 2)

# 初始化变量的op
init_op = tf.global_variables_initializer()

with tf.Session() as sess:
    # 初始化变量
    sess.run(init_op)

    # 线程协调器、线程管理员
    coord = tf.train.Coordinator()
    # 真正开启子线程,去做那些事
    threads = qr.create_threads(sess, coord=coord, start=True)
    # 主线程，不断的去从队列中读取数据
    for i in range(300):
        print(sess.run(Q.dequeue()))
    # 回收子线程
    coord.request_stop()
    coord.join(threads)
```

运行结果如下：
```bash
24.0
300.0
524.0
668.0
1001.0
1002.0
1003.0
...
1294.0
1295.0
1296.0
```



# tensorflow读取数据

[tensorflow中文社区|读取数据参考文档]([http://www.tensorfly.cn/tfdoc/how_tos/reading_data.html](http://www.tensorfly.cn/tfdoc/how_tos/reading_data.html))

tensorflow可以读取以下三种形式的文件，不同类型文件的读取形式也不同，如下所示：

1. csv文件，读取一行
2. 二进制文件，指定一个样本的bytes读取
3. 图片文件，一张一张的读取

## 文件读取的流程

参考官网的文件读取流程图如下所示：

![img](assets/AnimatedFileQueues.gif)

## 文件读取的步骤

**1. 构造文件队列**

将需要读取的数据放入队列。

核心API
`tf.train.string_input_producer(string_tensor,,shuffle=True)`：将输出字符串（例如文件名）输入到管道队列

参数说明：

- string_tensor	含有文件名的1阶张量
- num_epochs:过几遍数据，默认无限过数据
- return:具有输出字符串的队列

**2. 新建文件阅读器**

我们通过文件阅读器去读取数据。

根据文件格式，选择对应的文件阅读器:
`class tf.TextLineReader`：阅读文本文件逗号分隔值（CSV）格式,默认按行读取
return：读取器实例

`tf.FixedLengthRecordReader(record_bytes)`：要读取每个记录是固定数量字节的二进制文件
record_bytes:整型，指定每次读取的字节数
return：读取器实例

`tf.TFRecordReader`：读取TfRecords文件。

这些阅读器都有一个共同的读取方法：`read(file_queue)`：从队列中指定数量内容，返回一个Tensors元组（key文件名字，value默认的内容(行，字节)）。

**3. 文件内容解码**

将读取到的数据进行解码。由于从文件中读取的是字符串，需要函数去解析这些字符串到张量
`tf.decode_csv(records,record_defaults=None,field_delim = None，name = None)`：将CSV转换为张量，与tf.TextLineReader搭配使用

参数说明：

- records:tensor型字符串，每个字符串是csv中的记录行
- field_delim:默认分割符”,”
- record_defaults:参数决定了所得张量的类型，并设置一个值在输入字符串中缺少使用默认值,如

`tf.decode_raw(bytes,out_type,little_endian = None，name = None) `：将字节转换为一个数字向量表示，字节为一字符串类型的张量,与函数`tf.FixedLengthRecordReader`搭配使用，二进制读取为uint8格式

**4. 批处理**

读取多个数据。

`tf.train.batch(tensors,batch_size,num_threads = 1,capacity = 32,name=None)`：读取指定大小（个数）的张量。

参数说明：

- tensors：可以是包含张量的列表
- batch_size:从队列中读取的批处理大小
- num_threads：进入队列的线程数
- capacity：整数，队列中元素的最大数量
- return:tensors

`tf.train.shuffle_batch(tensors,batch_size,capacity,min_after_dequeue,num_threads=1,) `：乱序读取指定大小（个数）的张量。

参数说明：

- min_after_dequeue:留下队列里的张量个数，能够保持随机打乱

**5. 开启线程操作**

开启子线程去执行读取文件的操作。

`tf.train.start_queue_runners(sess=None,coord=None)`：收集所有图中的队列线程，并启动线程。

参数说明：

- sess:所在的会话中
- coord：线程协调器
- return：返回所有线程队列

# tensorflow读取csv文件

- tensorflow读取单个csv文件
- tensorflow读取csv文件集

## 单个文件读取

数据格式如下：

```
0,10,0,0,0
0,15,0,0,1
0,30,0,0,2
0,45,0,0,3
```

完整代码如下：

```python
from __future__ import print_function
import tensorflow as tf
import os 
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

def file_len(fname):
    """
   获取文件的长度，也就是有多少行
    """
    with open(fname) as f:
        for i, l in enumerate(f):
            # i为行，从0开始
            # l为每行的内容，
            pass
    # i还在内存中，可以直接调用
    return i + 1

def readcsv(filename):
    """
    读取csv文件
    """
    # 1、构造一个读取文件的队列
    filename_queue = tf.train.string_input_producer([filename])
    # 2、构建一个csv阅读器，去读取数据
    reader = tf.TextLineReader(skip_header_lines=0)
    # 开始读取数据，返回2个值，第一个值为行号，第二个值为内容
    _, csv_row = reader.read(filename_queue)
    # 3、文件解码setup CSV decoding
    record_defaults = [[0],[0],[0],[0],[0]]
    col1,col2,col3,col4,col5 = tf.decode_csv(csv_row, record_defaults=record_defaults)
    # turn features back into a tensor
    features = tf.stack([col1,col2,col3,col4])
    print("loading, " + str(file_length) + " line(s)\n")
    return features, col5

# 要读取的数据文件
filename = "csv_test_data.csv"
# 获取文件长度
file_length = file_len(filename)
# 读取文件
features,col5 = readcsv(filename)

with tf.Session() as sess:
    # 初始化变量
    tf.initialize_all_variables().run()

    # 4、开启线程操作
    # start populating filename queue
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    for i in range(file_length):
        # 5、打印运行的结果
        # retrieve a single instance
        example, label = sess.run([features, col5])
        print(example, label)

    coord.request_stop()
    coord.join(threads)
```

运行结果如下所示：

```bash
[ 0 10  0  0] 0
[ 0 15  0  0] 1
[ 0 30  0  0] 2
[ 0 45  0  0] 3
```

## 读取csv文件集

在当前目录下的`data_csv/`文件夹中有3个csv文件，分别为`a.csv`、`b.csv`、`c.csv`，三个文件的内容如下所示：

a.csv

```
a1,20
a2,21
a3,22
```

b.csv

```
b1,15
b2,16
b3,17
```

c.csv

```
c1,15
c2,17
c3,19
```

完整代码如下所示：

```python
import tensorflow as tf
import os

def csvread(filelist):
    """
    读取CSV文件
    :param filelist: 文件路径+名字的列表
    :return: 读取的内容
    """
    # 1、构造文件的队列
    file_queue = tf.train.string_input_producer(filelist)

    # 2、构造csv阅读器读取队列数据（按一行）
    reader = tf.TextLineReader()
    # 读取数据，key为行号，value为每一行的内容
    key, value = reader.read(file_queue)

    # 3、对每行内容解码
    # record_defaults:指定每一个样本的每一列的类型，指定默认值[["None"], [4.0]]
    records = [["None"], [0]]
    example, label = tf.decode_csv(value, record_defaults=records)

    # 4、想要读取多个数据，就需要批处理
    # 一般capacity设置和batch_size一样，或者比它大。
    example_batch, label_batch = tf.train.batch([example, label], batch_size=9, num_threads=1, capacity=9)

    return example_batch, label_batch

if __name__ == "__main__":
    file_name = os.listdir("data_csv/")
    filelist = [os.path.join("data_csv/", file) for file in file_name]

    example_batch, label_batch = csvread(filelist)

    with tf.Session() as sess:
        # 初始化变量
        tf.initialize_all_variables().run()

        # 5、开启子线程
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)

        # 6、打印获取的数据
        print(sess.run([example_batch, label_batch]))

        # 关闭线程
        coord.request_stop()
        coord.join(threads)
```

运行结果如下所示：

```bash
[array([b'a1', b'a2', b'a3', b'c1', b'c2', b'c3', b'b1', b'b2', b'b3'],
      dtype=object), array([20, 21, 22, 15, 17, 19, 15, 16, 17], dtype=int32)]
```



# tensorflow读取图片

## 图像基本知识

**图像三要素**
图像三要素：长度(height)、宽度(width)、通道数(channels)，我们可以使用一个3-D张量来表示：[height,width,channels]
说明：通道数为1，表示灰度值；通道数为3，表示RGB。

一般在拿到图片数据集后，我们都会对图片进行一些处理，指定3-D的shape大小，我们会将所有的图片进行缩放处理，变成统一大小的图片。

在处理图片数据的时候，我们最后会把数据包装成4-D张量：[nums,height,width,channels]，第一个值为样本数，如下所示：

`Tensor("batch:0", shape=(300, 200, 200, 1), dtype=float32)`

## 核心API

### 缩小图片

```
# 缩小图片
tf.image.resize_images(images, size)
```

参数说明：

- images：4-D形状[batch, height, width, channels]或3-D形状的张量[height, width, channels]的图片数据。
- size：1-D int32张量：new_height, new_width，图像的新尺寸返回4-D格式或者3-D格式图片。

### 图像读取API

**图像读取器**

```
# 将文件的全部内容作为值输出的读取器。
tf.WholeFileReader
```

参数说明：

- return：读取器实例

**WholeFileReader相关方法**

```
# 输出将是一个文件名（key）和该文件的内容（值）
read(file_queue)
```

**图像解码器**

```
# 将JPEG编码的图像解码为uint8张量
tf.image.decode_jpeg(contents)
```

参数说明：

- return:uint8张量，3-D形状[height, width, channels]

```
# 将PNG编码的图像解码为uint8或uint16张量
tf.image.decode_png(contents)
```

参数说明：

- return:张量类型，3-D形状[height, width, channels]

## 图片处理流程

1. 构造图片文件队列
2. 构造文件阅读器
3. 读取图片数据
4. 批处理图片
5. 在TensorFlow中运行

## 示例

```python
import tensorflow as tf
import os

def pictureRead(filelist):
    # 1、构造文件队列
    queue = tf.train.string_input_producer(filelist)

    # 2、构造阅读器去读取图片内容（默认读取一张图片）
    reader = tf.WholeFileReader()
    key,value = reader.read(queue)
    
    # Tensor("ReaderReadV2:1", shape=(), dtype=string)
    #print(value)

    # 3、解码
    images = tf.image.decode_jpeg(value)

    # Tensor("DecodeJpeg:0", shape=(?, ?, ?), dtype=uint8)
    #print(images)

    # 4、统一图片大小
    images_resize = tf.image.resize_images(images, [200, 200])

    # Tensor("resize/Squeeze:0", shape=(200, 200, ?), dtype=float32)
    #print(images_resize)

    # 注意：一定要把样本的形状固定 [200, 200, 1],在批处理的时候要求所有数据形状必须定义
    # 如果是RGB图片，设置成[200, 200, 3]
    images_resize.set_shape([200,200,1])

    # Tensor("resize/Squeeze:0", shape=(200, 200, 3), dtype=float32)
    #print(images_resize)

    # 5、批处理,获得4D tensor， 第一个为样本数量
    images_batch = tf.train.batch([images_resize], batch_size=300, num_threads=1, capacity=300)

    # Tensor("batch:0", shape=(50, 200, 200, 3), dtype=float32)
    #print(images_batch)
    return images_batch


if __name__ == "__main__":
    # 文件路径
    dir_mstar = "/Users/zhusheng/WorkSpace/Tmp/dataset/MSTAR/EOC-data/train/2S1-b01/"

    filenames = os.listdir(dir_mstar)
    filelist = [os.path.join(dir_mstar, file) for file in filenames]
    #print(filelist)
    
    images_batch = pictureRead(filelist)
    print(images_batch)

    with tf.Session() as sess:
        # 初始化变量
        sess.run(tf.local_variables_initializer())
        sess.run(tf.global_variables_initializer())
        
        # 开启线程去读取图片
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
        print(sess.run(images_batch))
        
        # 回收线程
        coord.request_stop()
        coord.join(threads)
```

运行效果如下所示：

```bash
[[[[ 64.      ]
   [ 22.129997]
   [ 59.140003]
   ...
   [ 53.759766]
   [ 74.63983 ]
   [128.      ]]
...
```





# tensorflow读取二进制文件

## 数据集

[数据集|The CIFAR-10 dataset,我们选择下载二进制版本](https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz)，该数据集有5* 10000个样本图片和10000个测试样本图片。相关介绍如下所示：

```
Binary version
The binary version contains the files data_batch_1.bin, data_batch_2.bin, ..., data_batch_5.bin, as well as test_batch.bin. Each of these files is formatted as follows:
<1 x label><3072 x pixel>
...
<1 x label><3072 x pixel>
In other words, the first byte is the label of the first image, which is a number in the range 0-9. The next 3072 bytes are the values of the pixels of the image. The first 1024 bytes are the red channel values, the next 1024 the green, and the final 1024 the blue. The values are stored in row-major order, so the first 32 bytes are the red channel values of the first row of the image. 

Each file contains 10000 such 3073-byte "rows" of images, although there is nothing delimiting the rows. Therefore each file should be exactly 30730000 bytes long. 

There is another file, called batches.meta.txt. This is an ASCII file that maps numeric labels in the range 0-9 to meaningful class names. It is merely a list of the 10 class names, one per row. The class name on row i corresponds to numeric label i.
```

每个图片包含一个标签和3072个像素，32 * 32=1024, 1024*3 = 3072，3072是通道为RGB 3通道。

## 读取二进制文件

### 步骤分析

1、构造文件队列

```python
file_queue = tf.train.string_input_producer(file_list)
```

2、创建文件阅读器

```python
reader = tf.FixedLengthRecordReader(bytes)
key, value = reader.read(file_queue)
```

这里的`bytes`也就是3073.

3、对读取的每一行内容进行解码，解码为unit8格式。

```
 label_image = tf.decode_raw(value, tf.uint8)
```

4、分割出图片和标签数据，切出特征值和目标值

```
label = tf.slice(label_image, [0], label_bytes)
label = tf.cast(label, tf.int32)
image = tf.slice(label_image, label_bytes, image_bytes)
```

5、转换图片形状。可以对图片的特征数据进行形状的改变 [3072] --> [32, 32, 3]

```
image_reshape = tf.reshape(image, [height, width, channel])
```

6、批处理数据。总样本数为10000 *5 = 50000，为了节省运行时间，我改为100

```
image_batch, label_batch = tf.train.batch([image_reshape, label], batch_size=100, num_threads=1, capacity=100)
```

### 完整代码

[read_binary.py](https://github.com/zhusheng/study/blob/master/tensorflow/codes/part2_read_data/read_binary.py)

```python
import tensorflow as tf
import os

"""
读取二进制文件
"""
# 定义cifar的数据等命令行参数
FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_string("cifar_dir", "/Users/zhusheng/WorkSpace/Tmp/dataset/cifar-10-batches-bin/", "文件的目录")
tf.app.flags.DEFINE_string("cifar_tfrecords", "./tmp/cifar.tfrecords", "存进tfrecords的文件")

# 图片的基本数据

height = 32
width = 32
channel = 3
label_bytes = 1
image_bytes = height * width * channel
bytes = label_bytes + image_bytes


def read_and_decode(file_list):
    """
    读取二进制文件
    :return:
    """
    # 1、构造文件队列
    file_queue = tf.train.string_input_producer(file_list)

    # 2、构造二进制文件读取器，读取内容, 每个样本的字节数
    reader = tf.FixedLengthRecordReader(bytes)
    key, value = reader.read(file_queue)
    print("value", value)

    # 3、解码内容, 二进制文件内容的解码
    label_image = tf.decode_raw(value, tf.uint8)
    print("label_image", label_image)

    # 4、分割出图片和标签数据，切出特征值和目标值
    label = tf.slice(label_image, [0], [label_bytes])
    label = tf.cast(label, tf.int32)
    image = tf.slice(label_image, [label_bytes], [image_bytes])
    print("label", label)
    print("image", image)

    # 5、可以对图片的特征数据进行形状的改变 [3072] --> [32, 32, 3]
    image_reshape = tf.reshape(image, [height, width, channel])
    print("image_reshape", image_reshape)

    # 6、批处理数据,总样本数为10000 *5 = 50000，为了节省运行时间，我改为100
    image_batch, label_batch = tf.train.batch([image_reshape, label], batch_size=100, num_threads=1, capacity=100)
    print("image_batch:", image_batch, "\nlabel_batch:", label_batch)
    return image_batch, label_batch


if __name__ == '__main__':
    # 找到文件，放入列表   路径+名字  ->列表当中
    file_name = os.listdir(FLAGS.cifar_dir)
    # 下载的数据集中，有一个test_batch.bin，我改了一下名称为test_batch.binn,方便删选
    # 取出后缀为bin的文件
    file_list = [os.path.join(FLAGS.cifar_dir, file) for file in file_name if file[-3:] == "bin"]
    print(file_list)

    # 读取数据
    image_batch, label_batch = read_and_decode(file_list)

    # 开启会话运行结果
    with tf.Session() as sess:
        # 定义一个线程协调器
        coord = tf.train.Coordinator()
        # 开启读文件的线程
        threads = tf.train.start_queue_runners(sess, coord=coord)

        # 打印读取的内容
        print(sess.run([image_batch, label_batch]))

        # 回收子线程
        coord.request_stop()
        coord.join(threads)
```

## TFRecords

### TFRecords简介

TFRecords是Tensorflow设计的一种*内置文件格式*，是一种二进制文件，
它能更好的利用内存，方便进行数据的复制和移动。

TFRecords存储的文件格式为：*.tfrecords，文件写入的内容为：Example协议块。

为了将二进制数据和标签(训练的类别标签)数据存储在同一个文件中。

### 步骤分析

写入步骤：

1. 构造存储器
2. 构造每一个样本的Example
3. 写入序列化的Example

读取步骤：

1. 构造TFRecords阅读器
2. 解析Example
3. 转换格式，bytes解码

### 核心API

1、建立TFRecord存储器

```python
# 将内容写入tfrecords文件
tf.python_io.TFRecordWriter(path)
```

参数说明：

- path：TFRecords文件的路径，例如：`"./tmp/cifar.tfrecords"`,是一个以`.tfrecords`结尾的文件。
- return：返回一个文件写入器对象。

相关方法：

```python
# 向文件中写入一个字符串记录。
write(record)
# 关闭文件写入器。
close()
```

2、构造每个样本的Example协议块

```python
# 写入tfrecords文件的内容是协议块
tf.train.Example(features=None)
```

参数说明：

- features：tf.train.Features类型的特征实例
- return：example格式协议块

```python
# 构建每个样本的信息键值对
tf.train.Features(feature=None)
```

参数说明：

- feature:字典数据,key为要保存的名字，value为tf.train.Feature实例
- return:Features类型

```python
features = tf.parse_single_example(value, features={
            "image": tf.FixedLenFeature([], tf.string),
            "label": tf.FixedLenFeature([], tf.int64),
        })
```

3、解析

解析TFRecords的example协议内存块

```python
# 解析一个单一的Example原型
tf.parse_single_example(serialized,features=None,name=None)
```

参数说明：

- serialized：标量字符串Tensor，一个序列化的Example
- features：dict字典数据，键为读取的名字，值为FixedLenFeature
- return:一个键值对组成的字典，键为读取的名字

```python
tf.FixedLenFeature(shape,dtype)
```

参数说明：

- shape：输入数据的形状，一般不指定,为空列表
- dtype：输入数据类型，与存储进文件的类型要一致，类型只能是float32,int64,string。

### TFRecord写入完整代码

[read_binary2.py](https://github.com/zhusheng/study/blob/master/tensorflow/codes/part2_read_data/read_binary2.py)

```python
import tensorflow as tf
import os

"""
保存数据到TFRecords
"""
# 定义cifar的数据等命令行参数
FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_string("cifar_dir", "/Users/zhusheng/WorkSpace/Tmp/dataset/cifar-10-batches-bin/", "文件的目录")
tf.app.flags.DEFINE_string("cifar_tfrecords", "./tmp/cifar.tfrecords", "存进tfrecords的文件")


# 图片的基本数据
height = 32
width = 32
channel = 3
label_bytes = 1
image_bytes = height * width * channel
bytes = label_bytes + image_bytes


def read_and_decode(file_list):
    """
    读取二进制文件
    :return:
    """
    # 1、构造文件队列
    file_queue = tf.train.string_input_producer(file_list)

    # 2、构造二进制文件读取器，读取内容, 每个样本的字节数
    reader = tf.FixedLengthRecordReader(bytes)
    key, value = reader.read(file_queue)
    print("value", value)

    # 3、解码内容, 二进制文件内容的解码
    label_image = tf.decode_raw(value, tf.uint8)
    print("label_image", label_image)

    # 4、分割出图片和标签数据，切出特征值和目标值
    label = tf.slice(label_image, [0], [label_bytes])
    label = tf.cast(label, tf.int32)
    image = tf.slice(label_image, [label_bytes], [image_bytes])
    print("label", label)
    print("image", image)

    # 5、可以对图片的特征数据进行形状的改变 [3072] --> [32, 32, 3]
    image_reshape = tf.reshape(image, [height, width, channel])
    print("image_reshape", image_reshape)

    # 6、批处理数据,总样本数为10000 *5 = 50000，为了节省运行时间，我改为100
    image_batch, label_batch = tf.train.batch([image_reshape, label], batch_size=100, num_threads=1, capacity=100)
    print("image_batch:", image_batch, "\nlabel_batch:", label_batch)
    return image_batch, label_batch


def convert_to_tfrecords(image_batch, label_batch, file_path):
    """
    将图片的特征值和目标值存进tfrecords
    :param image_batch:
    :param label_batch:
    :return:
    """
    # 1、建立TFRecords存储器
    writer = tf.python_io.TFRecordWriter(file_path)

    # 2、循环将所有样本写入文件中，每张图片都要构造example协议
    for i in range(10):
        # 取出第i个图片的数据的特征值和目标值
        image = image_batch[i].eval().tostring()
        label = int(label_batch[i].eval()[0])

        # 构造一个样本的example
        example = tf.train.Example(features=tf.train.Features(feature={
            "image": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),
            "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),
        }))

        # 写入单独的样本
        writer.write(example.SerializeToString())

    # 关闭
    writer.close()


if __name__ == '__main__':
    # 找到文件，放入列表   路径+名字  ->列表当中
    file_name = os.listdir(FLAGS.cifar_dir)
    # 下载的数据集中，有一个test_batch.bin，我改了一下名称为test_batch.binn,方便删选
    # 取出后缀为bin的文件
    file_list = [os.path.join(FLAGS.cifar_dir, file) for file in file_name if file[-3:] == "bin"]
    print(file_list)

    # 读取二进制数据
    image_batch, label_batch = read_and_decode(file_list)

    # 开启会话运行结果
    with tf.Session() as sess:
        # 定义一个线程协调器
        coord = tf.train.Coordinator()
        # 开启读文件的线程
        threads = tf.train.start_queue_runners(sess, coord=coord)

        # 打印读取的内容
        #print(sess.run([image_batch, label_batch]))

        # 将数据存储到TFRecords存储器中
        print("开始存储")
        convert_to_tfrecords(image_batch, label_batch, FLAGS.cifar_tfrecords)
        print("结束存储")

        # 回收子线程
        coord.request_stop()
        coord.join(threads)
```

### TFRecord读取完整代码

[read_binary3.py](https://github.com/zhusheng/study/blob/master/tensorflow/codes/part2_read_data/read_binary3.py)

```python
import tensorflow as tf
import os

"""

从TFRecord中读取数据

"""

# 定义cifar的数据等命令行参数
FLAGS = tf.app.flags.FLAGS
tf.app.flags.DEFINE_string("cifar_dir", "/Users/zhusheng/WorkSpace/Tmp/dataset/cifar-10-batches-bin/", "文件的目录")
tf.app.flags.DEFINE_string("cifar_tfrecords", "./tmp/cifar.tfrecords", "存进tfrecords的文件")


image_bytes = 32 * 32 * 3

def read_from_tfrecords(file_path):
    """
    读取tfrecords
    :return: None
    """
    file_queue = tf.train.string_input_producer([file_path, ])

    reader = tf.TFRecordReader()

    key, value = reader.read(file_queue)

    features = tf.parse_single_example(value, features={
        "image": tf.FixedLenFeature([], tf.string),
        "label": tf.FixedLenFeature([], tf.int64),
    })
    # 对读取的内容进行解码
    image = tf.decode_raw(features["image"], tf.uint8)

    # 设置静态形状，可用于转换动态形状
    image.set_shape([image_bytes])
    print(image)

    image_tensor = tf.reshape(image, [32, 32, 3])
    print(image_tensor)

    label = tf.cast(features["label"], tf.int32)
    print(label)

    image_batch, label_batch = tf.train.batch([image_tensor, label], batch_size=10, num_threads=1, capacity=10)
    print(image_batch)
    print(label_batch)

    return image_batch, label_batch


if __name__=="__main__":

    # 从TFRecord文件中读取数据，首先得有这个文件，我们先往里面保存数据。
    image_batch, label_batch = read_from_tfrecords(FLAGS.cifar_tfrecords)

    with tf.Session() as sess:
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)

        print(sess.run([image_batch, label_batch]))

        coord.request_stop()
        coord.join(threads)

```

